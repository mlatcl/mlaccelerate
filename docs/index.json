[{"authors":null,"categories":null,"content":"Jessica is currently Executive Director of the Accelerate Programme for Scientific Discovery, a new initiative developing AI tools and collaborations to tackle scientific challenges. She is also Director of the Data Trusts Initiative, a project tackling the actions needed to create trustworthy data governance frameworks.\nHer interests in AI and its consequences for science and society stem from her policy career, in which she worked with parliamentarians, leading researchers and civil society organisations to bring scientific evidence to bear on major policy issues. At the Royal Society, Jessica established and led a wide-ranging programme of policy development, public dialogue and international engagement that explored the frontiers of AI technologies and their implications for society. She worked with senior researchers, policymakers, civil society and industry to identify emerging policy needs and develop policy frameworks to enable safe and rapid deployment of these technologies. In her prior role as a Senior Clerk at the House of Commons, Jessica advised MPs on parliamentary procedure and practice. While advising a number of select committees – including Transport; Business, Innovation, and Skills; Regulatory Reform; and Science and Technology – Jessica managed inquiries into a range of science and policy issues, bringing evidence into the heart of political decision-making.\n","date":1610663284,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663284,"objectID":"f8885fa28f31756f147ee2f6cc2b1925","permalink":"https://mlatcl.github.io/mlaccelerate/author/jessica-montgomery/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/jessica-montgomery/","section":"authors","summary":"Jessica is currently Executive Director of the Accelerate Programme for Scientific Discovery, a new initiative developing AI tools and collaborations to tackle scientific challenges. She is also Director of the Data Trusts Initiative, a project tackling the actions needed to create trustworthy data governance frameworks.","tags":null,"title":"Jessica Montgomery","type":"authors"},{"authors":null,"categories":null,"content":"Neil Lawrence is the inaugural DeepMind Professor of Machine Learning at the University of Cambridge. He has been working on machine learning models for over 20 years. He recently returned to academia after three years as Director of Machine Learning at Amazon. His main interest is the interaction of machine learning with the physical world. This interest was triggered by deploying machine learning in the African context, where ‘end-to-end’ solutions are normally required. This has inspired new research directions at the interface of machine learning and systems research, this work is funded by a Senior AI Fellowship from the Alan Turing Institute. Neil is also visiting Professor at the University of Sheffield and the co-host of Talking Machines.\n","date":1610663284,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663284,"objectID":"17a38ba4b0f1230b9b0b493908dff8f2","permalink":"https://mlatcl.github.io/mlaccelerate/author/neil-d.-lawrence/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/neil-d.-lawrence/","section":"authors","summary":"Neil Lawrence is the inaugural DeepMind Professor of Machine Learning at the University of Cambridge. He has been working on machine learning models for over 20 years. He recently returned to academia after three years as Director of Machine Learning at Amazon.","tags":null,"title":"Neil D. Lawrence","type":"authors"},{"authors":null,"categories":null,"content":"I am researching methods for improving the representations learned by machine learning models through the use of uncertainty and information sharing. Uncertainty is needed because real-world data is noisy and our modeling assumptions are imperfect. Complementary, information sharing techniques like transfer learning and multi-view learning allow models to learn from diverse sources. The machine learning tools I am using in my research come from the Bayesian probabilistic or the deep learning domain, but I also investigate methods combining these areas. I have worked in a variety of application areas, such as: multi-modal information fusion, decision making, information retrieval, AI-assisted data science.\n","date":1611706003,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1611706003,"objectID":"50dab74fd5c08f3c41644177601b2673","permalink":"https://mlatcl.github.io/mlaccelerate/author/andreas-damianou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/andreas-damianou/","section":"authors","summary":"I am researching methods for improving the representations learned by machine learning models through the use of uncertainty and information sharing. Uncertainty is needed because real-world data is noisy and our modeling assumptions are imperfect.","tags":null,"title":"Andreas Damianou","type":"authors"},{"authors":null,"categories":null,"content":"I work with probabilistic models, particularly with Gaussian processes. My interest lies in Bayesian machine learning, Bayesian optimisation, latent variable models and automatic machine learning (automl). I am also pursuing research aiming at improving human-level interpretability in machine learning models. I have explored the intersection of Probabilistic Modelling and Geometry, with a special attention to the behaviour of metrics in probabilistic geometries.\n","date":1610663284,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663284,"objectID":"e9b7ebe61ebc863fae793d8e682848ce","permalink":"https://mlatcl.github.io/mlaccelerate/author/alessandra-tosi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/alessandra-tosi/","section":"authors","summary":"I work with probabilistic models, particularly with Gaussian processes. My interest lies in Bayesian machine learning, Bayesian optimisation, latent variable models and automatic machine learning (automl). I am also pursuing research aiming at improving human-level interpretability in machine learning models.","tags":null,"title":"Alessandra Tosi","type":"authors"},{"authors":null,"categories":null,"content":"Professor Yang-Hui He is a mathematical physicist working on the interface between geometry, number theory and quantum field theory/string theory. Recently, he helped introduce machine-learning into the field of pure mathematics by using AI to help uncover new patterns and raise new conjectures (cf. interview by Science [Vol 365, July, 2019] and by New Scientist [Dec 9 Issue, 2019]).\nYang studied at Princeton University, where he received his Bachelor of Arts in Physics, with a Certificate in Applied Mathematics and a Certificate in Engineering, Summa cum Laude (Highest Honours, Phi-Beta-Kappa). He then obtained a Certificate in Advanced Mathematics (Tripos) at the University of Cambridge, with Distinction. He went on to receive his PhD in theoretical and mathematical physics from MIT. Yang continued with postdoctoral work in the University of Pennsylvania before joining University of Oxford as the FitzJames Fellow in Mathematics and then the UK STFC Advanced Fellow in theoretical physics.\n","date":1610663284,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663284,"objectID":"da86a73ab5e6c56bdc30a5b25e4dfaa6","permalink":"https://mlatcl.github.io/mlaccelerate/author/yang-hui-he/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/yang-hui-he/","section":"authors","summary":"Professor Yang-Hui He is a mathematical physicist working on the interface between geometry, number theory and quantum field theory/string theory. Recently, he helped introduce machine-learning into the field of pure mathematics by using AI to help uncover new patterns and raise new conjectures (cf.","tags":null,"title":"Yang-Hui He","type":"authors"},{"authors":null,"categories":null,"content":"My research focuses on the development of probabilistic machine learning methods for uncertainty quantification and data-efficient sequential decision making. I work on the challenges arising when uncertainty of different types (the loss of precision induced by numerical calculations, data errors, model miss-calibration, etc.) need to be be propagated, controlled and reduced in complex pipelines. I am also interested on how causal inference can be used to leverage decision making methods and to improve the understanding of complex systems and processes. As fields of application of my research I am interested in computational biology, health and environmental sciences.\n","date":1610663285,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663285,"objectID":"f75a0563f7645838412dd42892506eca","permalink":"https://mlatcl.github.io/mlaccelerate/author/javier-gonazales/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/javier-gonazales/","section":"authors","summary":"My research focuses on the development of probabilistic machine learning methods for uncertainty quantification and data-efficient sequential decision making. I work on the challenges arising when uncertainty of different types (the loss of precision induced by numerical calculations, data errors, model miss-calibration, etc.","tags":null,"title":"Javier Gonazales","type":"authors"},{"authors":null,"categories":null,"content":"Challenger is a theoretical physicist working on the long-standing problem of quantising gravity. Recently, he started to undertake work in Theoretical Machine Learning, in order to exploit its tools to understand String Theory as a problem in big data. As a Rhodes Scholar he has pursued his passion in understanding fundamental physical processes by undertaking doctoral work in String Theory at the Rudolf Peierls Centre for Theoretical Physics, University of Oxford. During his recently completed thesis, he worked on understanding various aspects of complex geometries that feature in String Theory, using the tools of differential and algebraic-geometry. Prior to this, Challenger completed his undergraduate work in Physics from the Indian Institute of Science Education and Research, Kolkata. During his undergraduate years, he worked on a NASA-sponsored project applying stochastic optimisation techniques to analyse data from the proposed gravitaional wave detector, LISA.\n","date":1610663285,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663285,"objectID":"661f8454c7bbd3c300fe931ab90afa89","permalink":"https://mlatcl.github.io/mlaccelerate/author/challenger-mishra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/challenger-mishra/","section":"authors","summary":"Challenger is a theoretical physicist working on the long-standing problem of quantising gravity. Recently, he started to undertake work in Theoretical Machine Learning, in order to exploit its tools to understand String Theory as a problem in big data.","tags":null,"title":"Challenger Mishra","type":"authors"},{"authors":null,"categories":null,"content":"I am a Postdoctoral Fellow in the Macosko Lab at the Stanley Center for Psychiatric Research within the Broad Institute of MIT and Harvard. I received my PhD in Mathematics and Statistics at Boston University, where I worked on complexity penalized methods with applications to modeling queueing systems, information retrieval from text, and network inference. I’m now focused on representation learning for single-cell RNA-seq and spatial data, driven by questions in neuroscience. I also co-organize the Models, Inference \u0026amp; Algorithms initiative.\n","date":1611702773,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1611702773,"objectID":"100b97dde8131c6941cbd3e57c3884d9","permalink":"https://mlatcl.github.io/mlaccelerate/author/aleksandrina-goeva/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/aleksandrina-goeva/","section":"authors","summary":"I am a Postdoctoral Fellow in the Macosko Lab at the Stanley Center for Psychiatric Research within the Broad Institute of MIT and Harvard. I received my PhD in Mathematics and Statistics at Boston University, where I worked on complexity penalized methods with applications to modeling queueing systems, information retrieval from text, and network inference.","tags":null,"title":"Aleksandrina Goeva","type":"authors"},{"authors":null,"categories":null,"content":"String theory is the leading candidate for a theory of quantum gravity. My interests are broad, but focus on bringing string theory into contact with the real world. In particular, motivated by the AdS/CFT correspondence and the principle of holography, I strive to formulate the theory of statistical mechanics that underlies gravitational thermodynamics. Black holes supply an important theoretical laboratory for this research. I want to apply the technology developed in the black hole context to the resolution of spacetime singularities, especially in time dependent, cosmological backgrounds. I aim to understand holography and the emergence of spacetime in general settings. Another major thrust of my research is to explain how the Standard Model of particle physics descends from a fundamental theory. I seek to relate geometrical aspects of the vacuum space of quantum field theories to string theory and use geometric structure as a practical tool for particle phenomenology. Recently, I have been investigating the constraints on string compactifications stemming from cosmology and particle theory inputs. As well, I work on supersymmetric field theories in four dimensions and various problems in mathematical physics.\n","date":1610663285,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663285,"objectID":"0c6c2f6fc17aafd09ff31661c46093c4","permalink":"https://mlatcl.github.io/mlaccelerate/author/vishnu-jejjala/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/vishnu-jejjala/","section":"authors","summary":"String theory is the leading candidate for a theory of quantum gravity. My interests are broad, but focus on bringing string theory into contact with the real world. In particular, motivated by the AdS/CFT correspondence and the principle of holography, I strive to formulate the theory of statistical mechanics that underlies gravitational thermodynamics.","tags":null,"title":"Vishnu Jejjala","type":"authors"},{"authors":null,"categories":null,"content":"His research is at some of the interfaces between string theory, particle physics, cosmology, mathematics, and deep learning. He is particularly interested in the string landscape and its implications for particle physics and cosmology beyond their standard models. These implications often follow from the structure of extra-dimensional geometries, of which there are many possibilities. Halverson’s research therefore requires importing techniques from mathematics and computer science.\nRecently, Halverson’s interest in the interface of physics and deep learning has continued to grow. To that end, he is a co-PI and serves on the institute board of the NSF AI Institute for Artificial Intelligence and Fundamental Interactions (IAIFI ) and co-organizes Physics ∩ ML.\n","date":1610663285,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663285,"objectID":"993c1f4166dae4fa714be129334a5c41","permalink":"https://mlatcl.github.io/mlaccelerate/author/jim-halverson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/jim-halverson/","section":"authors","summary":"His research is at some of the interfaces between string theory, particle physics, cosmology, mathematics, and deep learning. He is particularly interested in the string landscape and its implications for particle physics and cosmology beyond their standard models.","tags":null,"title":"Jim Halverson","type":"authors"},{"authors":null,"categories":null,"content":"My research focuses on encoding expert knowledge into hierarchical probabilistic models to facilitate inference and specify what to learn from data. Models become more data efficient and more trustworthy if the result of learning is a collection of expert-interpretable components. In my work, I explore how Bayesian non-parametric models can be composed to enforce abstract constraints, yield principled reasoning under uncertainty, and enable scalable and reliable inference.\n","date":1610663285,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610663285,"objectID":"7fb8c45633fc024d1253c9aa10f9e558","permalink":"https://mlatcl.github.io/mlaccelerate/author/markus-kaiser/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/markus-kaiser/","section":"authors","summary":"My research focuses on encoding expert knowledge into hierarchical probabilistic models to facilitate inference and specify what to learn from data. Models become more data efficient and more trustworthy if the result of learning is a collection of expert-interpretable components.","tags":null,"title":"Markus Kaiser","type":"authors"},{"authors":null,"categories":null,"content":"I am a Senior Lecturer in the Computer Laboratory at the University of Cambridge. The science of machine learning is concerned with how to formulate assumptions into mathematics (modelling) and how to related them to observed data (inference). My research focus spans both these areas, in specific I am interested in how we can specify data efficient and interpretable assumptions that allows us to learn from small amounts of data.\n","date":1610698036,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610698036,"objectID":"1c64c649275181f4ca1913708083d1bf","permalink":"https://mlatcl.github.io/mlaccelerate/author/carl-henrik-ek/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mlaccelerate/author/carl-henrik-ek/","section":"authors","summary":"I am a Senior Lecturer in the Computer Laboratory at the University of Cambridge. The science of machine learning is concerned with how to formulate assumptions into mathematics (modelling) and how to related them to observed data (inference).","tags":null,"title":"Carl Henrik Ek","type":"authors"},{"authors":["Jessica Montgomery"],"categories":null,"content":"Machine learning has the potential to become an engine for scientific discovery across disciplines – from predicting the impact of climate change, to using genetic data to create new healthcare treatments, and from finding new astronomical phenomena to identifying new materials here on Earth. Achieving this potential requires interdisciplinary collaborations that combine scientific insights with expertise in machine learning methods, creating machine learning systems that can be applied to ‘real-world’ problems. The Accelerate Programme for Scientific Discovery is a new initiative from Cambridge University’s Department of Computer Science and Technology, which will support researchers across the University to use machine learning to advance their research. This talk will introduce the thinking behind the Programme and its work.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611686114,"objectID":"defc78a2245c6829284047a7ed3c5543","permalink":"https://mlatcl.github.io/mlaccelerate/talk/jessica/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/jessica/","section":"talk","summary":"The Accelerate Programme for Scientific Discovery is a new initiative from Cambridge University’s Department of Computer Science and Technology, which will support researchers across the University to use machine learning to advance their research.","tags":["winterschool2021","day1"],"title":"AI for scientific discovery: an introduction to Accelerate Science","type":"talk"},{"authors":["Neil D. Lawrence"],"categories":null,"content":"With breakthroughs in understanding images, translating language, transcribing speech artificial intelligence promises to revolutionise the technological landscape. Machine learning algorithms are able to convert unstructured data into actionable knowledge. With the increasing impact of these technologies, society’s interest is also growing.\nThe word intelligence conjures notions of human-like capabilities. But are we really on the cusp of creating machines that match us? We associate intelligence with knowledge, but in this talk I will argue that the true marvel of our intelligence is the way it deals with ignorance.\nDespite the large strides forward we have made, I will argue that we have a long way to go to deliver on the promise of artificial intelligence. And it is a journey that our societies need to take together, not just as computer scientists, but together by rediscovering the interdisciplinary spirit that is required to achieve real scientific progress.\n  ","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612881916,"objectID":"342d9bdef6925bb040afbdf75bc76f67","permalink":"https://mlatcl.github.io/mlaccelerate/talk/neil/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/neil/","section":"talk","summary":"Is machine learning really artificial intelligence?","tags":["winterschool2021","day1"],"title":"What is Machine Intelligence?","type":"talk"},{"authors":["Carl Henrik Ek"],"categories":null,"content":"Machine learning is the science of combining knowledge with data through computation. In this talk we will try to make these concepts mathematically stringent. We will first discuss how we can formulate our knowledge mathematically by building models. Importantly differently from logic machine learning is concerned with knowledge that is uncertain often referred to as beliefs. We will show how we can use probabilities as a mean to quantify our beliefs. In the second part of the talk we will see how we can combine our beliefs with observations and recover an updated belief. We will discuss the interplay between data and beliefs this will become important when choosing which machine learning method to use for different scenarios.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612893345,"objectID":"fd1f0a771e078c06127e3b158fb76f7e","permalink":"https://mlatcl.github.io/mlaccelerate/talk/che/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/che/","section":"talk","summary":"This talk will focus on how we can formulate beliefs and assumptions mathematically and recover an updated belief from observations. We will reflect on the place machine learning can have in the scientific toolbox.","tags":["winterschool2021","day1"],"title":"Machine Learning and the Scientific Principle","type":"talk"},{"authors":["Andreas Damianou"],"categories":null,"content":"A machine learning model exploits patterns in the training data to generate an abstraction of the application domain. The knowledge stored inside a model is incomplete, since the model is imperfectly designed and the data fed to it are only a small and possibly biased sample of the full data distribution. Therefore, for many applications it is useful to also quantify the lack of knowledge associated with the model. This can help the training of the model itself but it can also transform predictions into probabilistic expectations which can drive more robust decision making. For example, it is very useful to have uncertainty communicated by a machine learning system which analyses patient data to suggest treatments. In this talk, I will discuss the various sources of uncertainty in a modeling scenario, motivate probabilistic methods for quantifying uncertainty, and explain how uncertainty can be used as an essential part of machine learning-assisted reasoning.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612538183,"objectID":"37172ad712209bdf7c8ffb2341ee5d29","permalink":"https://mlatcl.github.io/mlaccelerate/talk/andreasdamianou/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/andreasdamianou/","section":"talk","summary":"Humans understand, reason and act by quantifying not only what they know, but also what they do not know. The parallel to this in the machine learning world is quantification of uncertainty, and its propagation across the various components of our machine learning system. This talk will discuss the different sources of uncertainty arising in a modeling scenario, and the tools we can use to capture this uncertainty and use it as part of our machine learning-assisted reasoning.","tags":["winterschool2021","day1"],"title":"The Role of Uncertainty in Machine Learning","type":"talk"},{"authors":["Markus Kaiser"],"categories":null,"content":"Machine learning is a powerful tool to find explanations for data, but not all explanations are created equal. This talk will explore why collaboration with domain experts is critical for the successful application of machine learning in the industrial and scientific domains. We will focus on the expert-driven formulation and evaluation of hierarchical models and show how to specify what should be learned from data and how to apply the scientific principle to gain new and semantic insights.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612535923,"objectID":"145090d0dbaf8bab8e2c13c59fe0c9be","permalink":"https://mlatcl.github.io/mlaccelerate/talk/markuskaiser/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/markuskaiser/","section":"talk","summary":"Machine learning is a powerful tool to find explanations for data, but not all explanations are created equal. This talk will explore why collaboration with domain experts is critical for the successful application of machine learning in the industrial and scientific domains.","tags":["winterschool2021","day2"],"title":"Hierarchical models for insightful machine learning","type":"talk"},{"authors":["Alessandra Tosi"],"categories":null,"content":"   Optimisation techniques are widely used to solve problems across any domain. In this talk we will focus on global optimisation of black-box functions using Bayesian optimisation, an iterative optimisation technique. We will explore how Bayesian optimisation can be used beyond the popular application of fine tuning the parameters of complex machine learning models and data science pipelines.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612893507,"objectID":"bae1799fb8baa193ef1981857d6b0e11","permalink":"https://mlatcl.github.io/mlaccelerate/talk/alessandratosi/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/alessandratosi/","section":"talk","summary":"In this talk we will focus on global optimisation of black-box functions using Bayesian optimisation, an iterative optimisation technique.","tags":["winterschool2021","day2"],"title":"Bayesian Optimisation: Sequential Decision Making Under Uncertainty","type":"talk"},{"authors":["Javier Gonazales"],"categories":null,"content":"Regression models can be useful in various ways. In this talk we will focus on how we can use them to compute causal effects, so we can augment our toolkit when reasoning about how the world around us works. We will review some basic concepts of causal reasoning and revisit some common statistical misconceptions that can easily avoided with proper causal thinking.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611667900,"objectID":"dfcbf400566a89f395ed81f0ebb7d548","permalink":"https://mlatcl.github.io/mlaccelerate/talk/javiergonzales/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/javiergonzales/","section":"talk","summary":"Regression models can be useful in various ways. In this talk we will focus on how we can use them to compute causal effects, so we can augment our toolkit when reasoning about how the world around us works. We will review some basic concepts of causal reasoning and revisit some common statistical misconceptions that can easily avoided with proper causal thinking.","tags":["winterschool2021","day2"],"title":"Regression, Causality, Statistical Paradoxes and other Fairy Tales","type":"talk"},{"authors":["Aleksandrina Goeva"],"categories":null,"content":"Inverse problems arise when we want to use data to extract an insight into the inner workings of a system. Such problems are often ill-posed, meaning that there are multiple explanations compatible with the observations and it is therefore necessary to constrain the problem to arrive at a concrete solution. High-throughput high-resolution genome-wide spatial transcriptomics data is a recent breakthrough technology presenting great promise for gaining insights into cellular interactions and tissue-level systems biology. Extracting biologically useful knowledge from this new data modality comes with a novel set of computational challenges. One such challenge is figuring out how much different cell types have contributed to each spatial point measured from the tissue. We will go step-by-step over a simple, intuitive and interpretable solution (manifested by a matrix factorization) that utilizes expert-annotated reference data of cell types to constrain this ill-posed inverse problem.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612536029,"objectID":"558f35717e2710a67768b7fdb5ac0fd1","permalink":"https://mlatcl.github.io/mlaccelerate/talk/aleksandrinagoeva/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/aleksandrinagoeva/","section":"talk","summary":"Inverse problems arise when we want to use data to extract an insight into the inner workings of a system. Such problems are often ill-posed, meaning that there are multiple explanations compatible with the observations and it is therefore necessary to constrain the problem to arrive at a concrete solution.","tags":["winterschool2021","day2"],"title":"Inverse Problems in Biology, Deconvolution of Mixed Signals in Spatial Transcriptomics Data, and How to Use Matrix Factorization for Nearly Everything","type":"talk"},{"authors":["Yang-Hui He"],"categories":null,"content":"We briefly overview how historically string theory led theoretical physics first to algebraic/differential geometry, and then to computational geometry, and now to data science. Using the Calabi-Yau landscape - accumulated by the collaboration of physicists, mathematicians and computer scientists over the last 4 decades - as a starting-point and concrete playground, we then launch to review our recent program in machine-learning mathematical structures and address the tantalizing question of how AI helps doing mathematics, ranging from geometry, to representation theory, to combinatorics, to number theory.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612893393,"objectID":"58ba7445368484f1840f2d8e67e0230f","permalink":"https://mlatcl.github.io/mlaccelerate/talk/yanghuihe/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/yanghuihe/","section":"talk","summary":"We briefly overview how historically string theory led theoretical physics first to algebraic/differential geometry, and then to computational geometry, and now to data science.","tags":["winterschool2021","day3"],"title":"Universes are Big Data: from geometry, to physics, to ML","type":"talk"},{"authors":["Jim Halverson"],"categories":null,"content":"Recent advances in machine learning have begun creating new bridges to physics and mathematics that have traditionally existed between the latter two. Given this progress, I will speculate about where we are and where things might be headed, including through the recently launched NSF AI Institute for Artificial Intelligence and Fundamental Interactions. Specifically, I’ll survey well-known machine learning results in supervised learning, reinforcement learning, and generative models, and explain cases where these techniques are already impacting physics and math. In more detail, I will explain some remarkable similarities between neural networks and quantum field theory that might point towards a theoretical understanding of deep learning, and also how an AI agent’s ability to unknot headphones might provide useful in cracking a foundational problem in topology.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612893402,"objectID":"526dc190544f39e36cfdc8f150f4d7fe","permalink":"https://mlatcl.github.io/mlaccelerate/talk/jimhalverson/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/jimhalverson/","section":"talk","summary":"Recent advances in machine learning have begun creating new bridges to physics and mathematics that have traditionally existed between the latter two. Given this progress, I will speculate about where we are and where things might be headed, including through the recently launched NSF AI Institute for Artificial Intelligence and Fundamental Interactions.","tags":["winterschool2021","day3"],"title":"A Triangle of Influence: Bringing Together Physics, Pure Mathematics, and Computer Science","type":"talk"},{"authors":null,"categories":null,"content":"In this talk, we motivate string theory as a candidate theory of quantum gravity. The topology and geometry of the extra dimensions predicted by string theory determine aspects of the physics that we see every day. We use machine learning as a tool to probe this physics. We also use machine learning to explore the structure of the simplest quantum field theory. We conclude by giving prospects for the future of machine learning in theoretical physics and mathematics.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612893411,"objectID":"9c7f965e91ba8996e2786b6939e9aac0","permalink":"https://mlatcl.github.io/mlaccelerate/talk/vishnujejjala/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/vishnujejjala/","section":"talk","summary":"In this talk, we motivate string theory as a candidate theory of quantum gravity.","tags":["winterschool2021","day3"],"title":"Machine Learning as a Discovery Tool","type":"talk"},{"authors":["Challenger Mishra"],"categories":null,"content":"Quantum chromodynamics (QCD) is the theory of the strong interaction. The fundamental particles of QCD, quarks and gluons, carry colour charge and form colourless bound states at low energies. The hadronic bound states of primary interest to us are the mesons and the baryons. From knowledge of the meson spectrum, we use neural networks and Gaussian processes to predict the masses of baryons with 90.3% and 96.6% accuracy, respectively. These results compare favourably to the constituent quark model. We as well predict the masses of pentaquarks and other exotic hadrons.\n","date":1580637600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612893419,"objectID":"8fb5e3a3c8318c785e3b9d72aeae0a38","permalink":"https://mlatcl.github.io/mlaccelerate/talk/challengermishra/","publishdate":"2020-02-02T10:00:00Z","relpermalink":"/mlaccelerate/talk/challengermishra/","section":"talk","summary":"Quantum chromodynamics (QCD) is the theory of the strong interaction. The fundamental particles of QCD, quarks and gluons, carry colour charge and form colourless bound states at low energies.","tags":["winterschool2021","day3"],"title":"Baryons from Mesons: A Machine Learning Perspective","type":"talk"}]